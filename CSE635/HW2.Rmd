---
title: "CSE 635-50 HW2"
author: "Miles Taylor"
date: "5/30/2022"
output: pdf_document
---


```{r setup, warning=FALSE, message=FALSE}
library(tidyverse)
library(kableExtra)
library(reticulate)
knitr::opts_chunk$set(echo = TRUE)
df = airquality
```

**Consider air quality data set with Ozone in parts per billion (ppb)as the dependent variable and Solar.R as the independent variable.**

Data was imported from the Air Quality data set available to all R users.


**Show the scatter plot of Ozone ~ Solar**

# Scatter Plot
```{r, scatterplot Solar.R vs. Ozone, warning=FALSE}

ggplot(data = df, aes(x = Solar.R, y = Ozone)) + 
  geom_point() + 
  ggtitle('Solar.R vs. Ozone') +
  xlab('Solar') +
  ylab('Ozone') + 
  theme_bw()


```

**Design the following 4 models:**   
1. Y1 = a + bX  
2. Y2 = a + bX + cX*X  
3. Y3 = e(a + bX)   
4. Y4 = e(a + bX + cX*X) 
     
# Model Development

```{r, Build Models, message=FALSE, warning=FALSE}
base_model <- lm(data = df, Ozone ~ Solar.R )
base_coef <- base_model$coefficients
x_sq <- df$Solar.R * df$Solar.R
xsq_model <- lm(data= df, Ozone ~ Solar.R + x_sq)
xsq_coef <- xsq_model$coefficients
log_model <- glm(data=df, Ozone ~ Solar.R, family = 'poisson')

log_model_coef <- log_model$coefficients
log_sq_model <- glm(data=df, Ozone ~ Solar.R + x_sq, family = 'poisson')
log_sq_model_coef <- log_sq_model$coefficients
  
```


```{python, Wrangle Models}
import pandas as pd
import numpy as np

py_df = r.df.copy()
py_df['Ozone'] = np.where(py_df.Ozone < -2147, np.nan, py_df.Ozone )
py_df['Solar.R'] = np.where(py_df['Solar.R'] < -2147, np.nan, py_df['Solar.R'])
lobf_base = pd.DataFrame([r.base_coef[1] * i + r.base_coef[0] for i in py_df['Solar.R']],
                                  columns = ['lobf_base'])
                                  
lobf_xsq = pd.DataFrame([ r.xsq_coef[2] * (i**2) + r.xsq_coef[1] * i + r.xsq_coef[0] 
                          for i in py_df['Solar.R']], columns = ['lobf_xsq'])

lobf_log = pd.DataFrame([ np.exp(r.log_model_coef[1] * i + r.log_model_coef[0]) 
                          for i in py_df['Solar.R']], columns = ['lobf_log'])

lobf_log_x2 = pd.DataFrame([np.exp(r.log_sq_model_coef[2] * (i**2) + 
                            r.log_sq_model_coef[1] * i + r.log_sq_model_coef[0]) 
                            for i in py_df['Solar.R']], columns = ['lobf_log_x2'])


model_1 = pd.concat([lobf_base, py_df.Ozone], axis = 1)
model_1['model_name'] = 'a + bX'
model_2 = pd.concat([lobf_xsq, py_df.Ozone], axis = 1)
model_2['model_name'] = 'a + bX + cX*X'
model_3 = pd.concat([lobf_log, py_df.Ozone], axis = 1)
model_3['model_name'] = 'e(a + bX)'
model_4 = pd.concat([lobf_log_x2, py_df.Ozone], axis = 1)
model_4['model_name'] = 'e(a + bX + cX*X)'

def regression_autopsy(predicted, actual, sequence_name):
  sst = np.sum((actual - actual.mean())**2 )
  ssr = np.sum((predicted - actual.mean()) **2)
  sse = np.sum((predicted - actual)**2)
  r_squared = ssr/sst * 100
  generate_payload = pd.DataFrame({'SST': [sst],
                                   'SSR': [ssr],
                                   'SSE': [sse],
                                   'R Squared': [r_squared] }) 
    
  generate_payload['diff'] = generate_payload.SST - generate_payload.SSR
  generate_payload['Errors Orthogonal?'] = np.where(generate_payload.diff == generate_payload.SSE,
                                                    'Yes', 'No')
  generate_payload.drop('diff', axis = 1, inplace= True)
  generate_payload['Name'] = sequence_name
  freeze_frame = generate_payload[['Name','SST',
                                  'SSR', 'SSE',
                                  'R Squared', 'Errors Orthogonal?']].copy()
  
  
  error = predicted - actual
  error_mean = error.mean()
  error_std = np.round(error.std(),2)
  errors_frame = pd.DataFrame({'Name': [sequence_name],
                               'Error Mean': [error_mean],
                               'Error Std' : [error_std] })
  
  return freeze_frame, errors_frame

model_list = [model_1, model_2, model_3, model_4]

all_the_models = []
all_the_errors = []
for model in model_list:
  fit, error = regression_autopsy(model.iloc[:,0], model.iloc[:,1], model.iloc[:,2][0] )
  all_the_models.append(fit)
  all_the_errors.append(error)
models_out = pd.concat(all_the_models)
errors_out = pd.concat(all_the_errors)
```

$~$

# Conclusions

$~$

**Evaluate these 4 models by computing R_sq and MSE in each case.**

```{r, Model Result Table, message=FALSE, warning=FALSE}
kbl(py$models_out)

```

$~$

The above table shows the SST, SSR, SSE, and R-squared for the
four models in contention. None of the models have errors that
are orthogonal to the independent variable, which means predictions
can be made but error term is correlated with the independent variable and may
result in high Std. Deviations, affecting the precision of our predictions.   

The next best step is to consider the R-squared of each model which describes 
how well the line of best fit
explains the variability of the independent variable. In this case, the
model e(a + bX + cX*X) performed the best and a + bX performed the worst.

$~$

**What are the best the worst model? Please explain your answer. **

```{r, Model Error Table,  message=FALSE, warning=FALSE}

kbl(py$errors_out)
```

$~$

The estimator for the beta coefficients is unbiased and efficient across
all the models - indicated by the presence of a 0 mean. The Std. Deviation
of the data sets give pause towards predictive power however. The model that performs
the best is still the e(a + bX + cX*X) and the model that performs the worst
is a + bX. 

Best Model: e(a + bX + cX*X)    
Worst Model: a + bX    
