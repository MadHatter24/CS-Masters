---
title: "CSE 635 - HW4"
author: "Miles Taylor"
date: "6/17/2022"
output: pdf_document
---

```{r setup, error=FALSE, message=FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(reticulate)
library(kableExtra)
library(broom)
```

## Reading a Comma-Separated Values (.csv) Data
 
```{r}
df <- read.csv("TitanicPassengers1.csv", skipNul= TRUE)
```
 
## Converting to survived column as a numeric value for a Linear Regression Model

```{python}
import pandas as pd
import numpy as np
nonulls = r.df.dropna().copy()
numeric_y = np.where(nonulls.Survived == 'Yes', 1, 0)

def transform_series_to_frame(series, actual, frame_name):
  make_frame = pd.DataFrame(series, columns = ['predicted'])
  make_frame['actuals'] = actual
  make_frame['name'] = frame_name
  
  return make_frame

def regression_autopsy(predicted, actual, sequence_name):
  sst = np.sum((actual - actual.mean())**2 )
  ssr = np.sum((predicted - actual.mean()) **2)
  sse = np.sum((predicted - actual)**2)
  r_squared = ssr/sst
  generate_payload = pd.DataFrame({'SST': [sst],
                                   'SSR': [ssr],
                                   'SSE': [sse],
                                   'R Squared': [r_squared] }) 
    
  generate_payload['diff'] = generate_payload.SST - generate_payload.SSR
  generate_payload['Errors Orthogonal?'] = np.where(generate_payload.diff == generate_payload.SSE,
                                                    'Yes', 'No')
  generate_payload.drop('diff', axis = 1, inplace= True)
  generate_payload['Name'] = sequence_name
  freeze_frame = generate_payload[['Name',  'SST', 'SSR',
                                   'SSE', 
                                  'R Squared']].copy()
  
  
  error = predicted - actual
  error_mean = error.mean()
  error_std = np.round(error.std(),2)
  errors_frame = pd.DataFrame({'Name': [sequence_name],
                               'Error Mean': [error_mean],
                               'Error Std' : [error_std] })
  
  return freeze_frame, errors_frame
```


## Running a Linear Regression Model using the best subset
 
```{r}
py$nonulls['survived_numeric'] <- py$numeric_y

model1a <- lm(data = py$nonulls, survived_numeric ~ Age)
model1a_predicted <- predict(model1a)
model1b <- lm(data = py$nonulls, survived_numeric ~ Age + Pclass)
model1b_predicted <- predict(model1b)
model1c <- lm(data = py$nonulls, survived_numeric ~ Age + Pclass + Sex)
model1c_predicted <- predict(model1c)
model1d <- lm(data = py$nonulls, survived_numeric ~ Age + Pclass + Sex + Fare)
model1d_predicted <- predict(model1d)
model1e <- lm(data = py$nonulls, survived_numeric ~ Age + Pclass + Sex + Fare + Embarked)
model1e_predicted <- predict(model1e)
model1f <- lm(data = py$nonulls, survived_numeric ~ Age + Pclass + Sex + Embarked)
model1f_predicted <- predict(model1f)

```

```{python}

model1_series = [r.model1a_predicted, 
                r.model1b_predicted,
                r.model1c_predicted,
                r.model1d_predicted,
                r.model1e_predicted,
                r.model1f_predicted]

model_names = ['Age', 'Age + Pclass', 'Age + Pclass + Sex', 'Age + Pclass + Sex + Fare',
              'Age + Pclass + Sex + Fare + Embarked', 'Age + Pclass + Sex +  Embarked']
all_the_models = []
all_the_errors = []
iterator = 0

for model in model1_series:
  model_as_frame = transform_series_to_frame(model, nonulls.survived_numeric.values, model_names[iterator])
  fit, error = regression_autopsy(model_as_frame.iloc[:,0], model_as_frame.iloc[:,1], model_as_frame.iloc[:,2][0] )
  all_the_models.append(fit)
  all_the_errors.append(error)
  iterator += 1
models_out = pd.concat(all_the_models)
errors_out = pd.concat(all_the_errors)

```

All of the subsets of model 1 are below -- 

```{r, error=FALSE, message=FALSE, warning = FALSE}

py$models_out %>% kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover"),
                latex_options = "hold_position")


```


## LM Best Model - Summary Output
```{r}
predicted_values_model1 <- predict(model1f)
predicted_floor1 <- ifelse(predicted_values_model1 < 0.5, 0, 1)

tidy(summary(model1e)) %>% kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover"), 
                latex_options = "hold_position")

```



## Creating a confusion matrix and accuracy for lm
 
```{r}
confusion_matrix1 <- table(py$nonulls$survived_numeric, predicted_floor1)
confusion_matrix1 %>% kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover"), 
                latex_options = "hold_position")


```

The accuracy and probability of misclassifcation for model 1 is below -- 

```{r}
accuracy_confusion_matrix1 <- sum(diag(confusion_matrix1))/ sum(confusion_matrix1)
pmc_1 <- 1 - accuracy_confusion_matrix1


```


```{python}
report_metrics1 = pd.DataFrame.from_dict({'Accuracy': [r.accuracy_confusion_matrix1],
                                          'Missclassification %' : [r.pmc_1]})
```

```{r}

py$report_metrics1 %>% kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover"),latex_options = "hold_position") 

```


## Converting to survived column as a factor for a General Linear Regression Model

```{r}
factor_survived <- as.factor(py$nonulls$Survived)
```

 
## Running a Generalized Linear Regression Model with logit using the best subset
 
```{r}
model2a <- glm(factor_survived ~ py$nonulls$Age,family="binomial"("logit"))
model2a_predicted <- model2a$fitted.values
model2b <- glm(factor_survived ~ py$nonulls$Age + py$nonulls$Pclass,family="binomial"("logit"))
model2b_predicted <- model2b$fitted.values
model2c <- glm(factor_survived ~ py$nonulls$Age + py$nonulls$Pclass + py$nonulls$Sex ,family="binomial"("logit"))
model2c_predicted <- model2c$fitted.values
model2d <- glm(factor_survived ~ py$nonulls$Age + py$nonulls$Pclass + py$nonulls$Sex + py$nonulls$Fare ,family="binomial"("logit"))
model2d_predicted <- model2d$fitted.values
model2e <- glm(factor_survived ~ py$nonulls$Age + py$nonulls$Pclass + py$nonulls$Sex + py$nonulls$Fare + py$nonulls$Embarked,family="binomial"("logit"))
model2e_predicted <- model2e$fitted.values
model2f <- glm(factor_survived ~ py$nonulls$Age + py$nonulls$Pclass + py$nonulls$Sex  + py$nonulls$Embarked,family="binomial"("logit"))
model2f_predicted <- model2e$fitted.values
```


```{python}

model2_series = [r.model2a_predicted, 
                r.model2b_predicted,
                r.model2c_predicted,
                r.model2d_predicted,
                r.model2e_predicted,
                r.model2f_predicted]

model_names = ['Age', 'Age + Pclass', 'Age + Pclass + Sex', 'Age + Pclass + Sex + Fare',
              'Age + Pclass + Sex + Fare + Embarked',  'Age + Pclass + Sex +  Embarked']
all_the_models2 = []
all_the_errors2 = []
iterator2 = 0

for model in model2_series:
  model_as_frame = transform_series_to_frame(model, nonulls.survived_numeric.values, model_names[iterator2])
  fit2, error2 = regression_autopsy(model_as_frame.iloc[:,0], model_as_frame.iloc[:,1], model_as_frame.iloc[:,2][0] )
  all_the_models2.append(fit2)
  all_the_errors2.append(error2)
  iterator2 += 1
models_out2 = pd.concat(all_the_models2)
errors_out2 = pd.concat(all_the_errors2)

```

All of the subsets of model 2 are below -- 
```{r, error=FALSE, message=FALSE, warning = FALSE}

py$models_out2 %>%  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover"),
                latex_options = "hold_position")

```

$~$

## Logit Best Model - Summary Output

```{r}
tidy(model2f) %>% kable()  %>%
  kable_styling(bootstrap_options = c("striped", "hover"),
                latex_options = "hold_position")

predicted_values_model2 <- predict(model2f)
predicted_floor2 <- ifelse(predicted_values_model2 < 0.5, 0, 1)
```


## Creating a confusion matrix and accuracy for logit

 
```{r}
confusion_matrix2 <- table(py$nonulls$survived_numeric, predicted_floor2)
confusion_matrix2 %>% kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover"),
                latex_options = "hold_position")


```

The accuracy and probability of misclassifcation for model 2 is below -- 



```{r}
accuracy_confusion_matrix2 <- sum(diag(confusion_matrix2))/ sum(confusion_matrix2)
pmc_2 <- 1 - accuracy_confusion_matrix2


```

```{python}
report_metrics2 = pd.DataFrame.from_dict({'Accuracy': [r.accuracy_confusion_matrix2],
                                          'Missclassification %' : [r.pmc_2]})
```


```{r}
py$report_metrics2 %>% kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover"),latex_options = "hold_position") 
```

## Running a Generalized Linear Regression Model with probit using the best subset
 
```{r}
model3a <- glm(factor_survived ~ py$nonulls$Age,family="binomial"("probit"))
model3a_predicted <- model3a$fitted.values
model3b <- glm(factor_survived ~ py$nonulls$Age + py$nonulls$Pclass,family="binomial"("probit"))
model3b_predicted <- model3b$fitted.values
model3c <- glm(factor_survived ~ py$nonulls$Age + py$nonulls$Pclass + py$nonulls$Sex ,family="binomial"("probit"))
model3c_predicted <- model3c$fitted.values
model3d <- glm(factor_survived ~ py$nonulls$Age + py$nonulls$Pclass + py$nonulls$Sex + py$nonulls$Fare,family="binomial"("probit"))
model3d_predicted <- model3d$fitted.values
model3e <- glm(factor_survived ~ py$nonulls$Age + py$nonulls$Pclass + py$nonulls$Sex
              + py$nonulls$Fare + py$nonulls$Embarked,family="binomial"("probit"))
model3e_predicted <- model3e$fitted.values
model3f <- glm(factor_survived ~ py$nonulls$Age + py$nonulls$Pclass + py$nonulls$Sex
              +  py$nonulls$Embarked,family="binomial"("probit"))
model3f_predicted <- model3e$fitted.values


```


```{python}

model3_series = [r.model3a_predicted, 
                r.model3b_predicted,
                r.model3c_predicted,
                r.model3d_predicted,
                r.model3e_predicted,
                r.model3f_predicted]

model_names = ['Age', 'Age + Pclass', 'Age + Pclass + Sex', 'Age + Pclass + Sex + Fare',
              'Age + Pclass + Sex + Fare + Embarked', 'Age + Pclass + Sex + Embarked']
all_the_models3 = []
all_the_errors3 = []
iterator3 = 0

for model in model3_series:
  model_as_frame = transform_series_to_frame(model, nonulls.survived_numeric.values, model_names[iterator3])
  fit, error = regression_autopsy(model_as_frame.iloc[:,0], model_as_frame.iloc[:,1], model_as_frame.iloc[:,2][0] )
  all_the_models3.append(fit)
  all_the_errors3.append(error)
  iterator3 += 1
models_out3 = pd.concat(all_the_models3)
errors_out3 = pd.concat(all_the_errors3)

```

$~$

All of the subsets of model 3 are below -- 

```{r, error=FALSE, message=FALSE, warning = FALSE}

py$models_out3 %>%  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover"),
                latex_options = "hold_position")


```

## Probit Best Model - Summary Output


```{r}
tidy(model3f) %>% kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover"),
                latex_options = "hold_position")

predicted_values_model3 <- predict(model3f)
predicted_floor3 <- ifelse(predicted_values_model3 < 0.5, 0, 1)
```

## Creating a confusion matrix and accuracy for probit
 
```{r}
confusion_matrix3 <- table(py$nonulls$survived_numeric, predicted_floor3)
confusion_matrix3 %>% kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover"),
                latex_options = "hold_position")
```

```{r}
accuracy_confusion_matrix3 <- sum(diag(confusion_matrix3))/ sum(confusion_matrix3)
pmc_3 <- 1 - accuracy_confusion_matrix3

```
```{python}
report_metrics3 = pd.DataFrame.from_dict({'Accuracy': [r.accuracy_confusion_matrix3],
                                          'Missclassification %' : [r.pmc_3]})
```


```{r}

py$report_metrics3 %>% kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover"),latex_options = "hold_position") 
```

## Finding the best subset

Please see the tables above for comparisons of the subset with SSE and R-squared for each model.  

The best model specification is Age, Pclass, Sex, and Embarked as
independent variables for two reasons. The first reason is through an analysis of
the SSE for each model. Looking at the tabular outputs from each model, Age, Pclass, Sex, and Embarked and Age, Pclass, Sex, Fare, and Embarked have the lowest SSEs and narrows down the candidates to two possible models. The winner can be determined by looking at the p-values
from each regression model. In this case, Fare was found to be non significant at the 5%
level so it was removed from the model. It is important to look at the p-values for verification because the coefficient of determination (R^2) is not adjusted, so the SSR will always increase when new variables are added because there is more variation in the system. 
